<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Paper-[www 21]-Graph Contrastive Learning with Adaptive Augmentation | hahahaha哈士奇</title><meta name="keywords" content="对比学习,无监督"><meta name="author" content="Wangzhiqiang,1941686805@qq.com"><meta name="copyright" content="Wangzhiqiang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Paper-Graph Contrastive Learning with Adaptive Augmentation(www 21) ABSTRACT 对比学习已经成功应用在图无监督学习上，但是图增强方案的部分很关键但是很少被探索。作者**认为数据增强方案应该保留图的内在结构和属性信息，这将迫使模型学习对不重要节点和边上的扰动不敏感的表示。**然而，大多数现有方法采用统一的数据增强方案，如统一丢">
<meta property="og:type" content="article">
<meta property="og:title" content="Paper-[www 21]-Graph Contrastive Learning with Adaptive Augmentation">
<meta property="og:url" content="http://example.com/2022/06/29/Paper-[WWW%2021]%20Graph%20Contrastive%20Learning%20with%20Adaptive%20Augmentation/index.html">
<meta property="og:site_name" content="hahahaha哈士奇">
<meta property="og:description" content="Paper-Graph Contrastive Learning with Adaptive Augmentation(www 21) ABSTRACT 对比学习已经成功应用在图无监督学习上，但是图增强方案的部分很关键但是很少被探索。作者**认为数据增强方案应该保留图的内在结构和属性信息，这将迫使模型学习对不重要节点和边上的扰动不敏感的表示。**然而，大多数现有方法采用统一的数据增强方案，如统一丢">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/b36a188093daf2e64a217a84bf183201-nKO_1QyFh9o-2edcfd.jpg">
<meta property="article:published_time" content="2022-06-29T13:55:13.870Z">
<meta property="article:modified_time" content="2022-08-04T03:41:03.520Z">
<meta property="article:author" content="Wangzhiqiang">
<meta property="article:tag" content="对比学习">
<meta property="article:tag" content="无监督">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/b36a188093daf2e64a217a84bf183201-nKO_1QyFh9o-2edcfd.jpg"><link rel="shortcut icon" href="/img/2.png"><link rel="canonical" href="http://example.com/2022/06/29/Paper-[WWW%2021]%20Graph%20Contrastive%20Learning%20with%20Adaptive%20Augmentation/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"7YPRNTZSD2","apiKey":"09830cc4fa08aac22c5aaefcda4871be","indexName":"myIndex","hits":{"per_page":10},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容：${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":350},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Paper-[www 21]-Graph Contrastive Learning with Adaptive Augmentation',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-08-04 11:41:03'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="/css/icon.css" media="defer" onload="this.media='all'"><meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/atom.xml" title="hahahaha哈士奇" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/1f2e377def5c6672de0cdeed4b54c36d-201672716495120191-a103ac.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">42</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">30</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">22</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/9d2244833e878e2169062087c9ab0874-wallhaven-g72p87-af7e51.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">hahahaha哈士奇</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Paper-[www 21]-Graph Contrastive Learning with Adaptive Augmentation</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-06-29T13:55:13.870Z" title="发表于 2022-06-29 21:55:13">2022-06-29</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-08-04T03:41:03.520Z" title="更新于 2022-08-04 11:41:03">2022-08-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/www21/">www21</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>18分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Paper-[www 21]-Graph Contrastive Learning with Adaptive Augmentation"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="Paper-Graph-Contrastive-Learning-with-Adaptive-Augmentation-www-21">Paper-Graph Contrastive Learning with Adaptive Augmentation(www 21)</h2>
<h2 id="ABSTRACT">ABSTRACT</h2>
<p>对比学习已经成功应用在图无监督学习上，但是图增强方案的部分很关键但是很少被探索。作者**认为数据增强方案应该保留图的内在结构和属性信息，这将迫使模型学习对不重要节点和边上的扰动不敏感的表示。**然而，大多数现有方法采用统一的数据增强方案，如统一丢弃边缘和统一的打乱特征，导致性能欠佳。</p>
<p>本文提出了一种具有自适应增强的新型图对比表示学习方法，该方法结合了图的拓扑和语义方面的各种先验。</p>
<p>具体来说，在拓扑层面，我们设计了基于节点中心性度量的增强方案，以突出重要的连接结构。在节点属性级别，我们通过向不重要的节点特征添加更多噪声来破坏节点特征，强制模型识别底层语义信息。</p>
<h2 id="1-介绍">1. 介绍</h2>
<p>遵循着DGI，GMI 提出了两个节点级对比目标，以分别直接测量输入与节点和边的表示之间的 MI，而无需显式数据增强。</p>
<p>尽管图上的 CL 方法得到了蓬勃发展，但数据增强方案被证明是视觉表示学习的关键组成部分，但在现有文献中仍然很少探索。与可用于图像和文本的大量数据转换技术不同，在 CL 方法中定义图增强方案并非易事，因为由于非欧几里德属性，图要复杂得多。我们认为，上述方法中使用的增强方案有两个缺点。</p>
<ul>
<li>
<p>首先，在结构域或属性域中进行简单的数据增强，例如 DGI 中的特征改变，不足以为节点生成不同的邻域（即上下文），特别是当节点特征稀疏时，导致难以优化对比目标。</p>
</li>
<li>
<p>其次，之前的工作在执行数据增强时忽略了节点和边影响的差异。如果我们通过统一丢弃边来构建图视图，那么删除一些有影响的边会降低嵌入质量。数据增强策略应该适应输入图以反映其内在模式。</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/05/26/31a44e382be26c194591d6e9da932101-image-20220526170508799-9ffd4e.png" alt="image-20220526170508799"></p>
<p>在 GCA 中，我们首先通过对输入执行随机损坏来生成两个相关的图视图。然后，我们使用对比损失来训练模型，以最大化这两个视图中节点嵌入之间的一致性。具体来说，我们提出了一种拓扑和节点属性级别的联合数据增强方案，即去除边缘和掩蔽特征，为不同视图的节点提供不同的上下文，从而促进对比目标的优化。</p>
<p>此外，我们通过中心性度量来识别重要的边缘和特征维度。然后，在拓扑级别上，我们通过对不重要的边缘给予较大的移除概率来自适应地丢弃边缘，以突出重要的连接结构。在节点属性级别，我们通过向不重要的特征维度添加更多噪声来破坏属性，以强制模型识别底层语义信息。</p>
<p>本文的核心贡献有两个，总结如下：</p>
<ul>
<li>
<p>首先，我们提出了一个通用的对比框架，用于具有强大的自适应数据增强的无监督图表示学习。所提出的 GCA 框架在拓扑和属性级别上联合执行数据增强，以适应图结构和属性，这鼓励模型从两个方面学习重要特征。</p>
</li>
<li>
<p>其次，我们使用五个公共基准数据集在常用<strong>的线性评估协议</strong>下对节点分类进行了全面的实证研究。 GCA 始终优于现有方法，我们的无监督方法甚至在几个任务上超过了有监督的方法。</p>
</li>
</ul>
<h2 id="2-RELATED-WORK">2 RELATED WORK</h2>
<h3 id="2-1-Contrastive-Representation-Learning">2.1 Contrastive Representation Learning</h3>
<p>在自监督表示学习中很受欢迎，对比方法旨在通过对比正负样本来学习有区别的表示。</p>
<p>理论分析揭示了他们成功背后的原因。这些方法中使用的目标可以看作是最大化输入特征与其表示之间的 MI 下限。</p>
<p>然而，最近的工作表明，评估表示质量的下游性能可能在很大程度上取决于不仅在卷积架构中而且在 InfoMax 目标的特定估计器中编码的偏差。<strong>也就是说，InfoMax的评估器很重要。</strong></p>
<h3 id="2-2-Graph-Representation-Learning">2.2 Graph Representation Learning</h3>
<p>许多传统的无监督图表示学习方法也采用对比范式。</p>
<p>无监督表示学习之前的工作主要是吧先前的工作集中在局部对比模式上，这迫使邻居节点具有相似的嵌入。这种情况下的正样本是出现在同一个随机游走中的节点。例如，开创性工作 DeepWalk 使用噪声对比估计对节点共现对的概率进行建模。这些基于随机游走的方法被证明等价于分解某些形式的图邻近度。它过分强调在这些图形近似中编码的结构信息，并且还面临大规模数据集的严重缩放问题。此外，已知这些方法容易出错，并且超参数调整不当。</p>
<p>在 DGI 之后，GMI [30] 使用两个鉴别器直接测量输入与节点和边的表示之间的 MI，而无需数据增强； MVGRL [15]  提出通过执行节点扩散并将节点表示与增强的图摘要表示进行对比来学习节点级和图级表示。此外，GCC [34]  提出了一种基于对比学习的预训练框架。它提出通过基于随机游走对子图进行采样来构建多个图视图，然后使用多种特征工程方案学习模型权重。</p>
<p>然而，这些方法没有明确考虑结构和属性级别的自适应图增强，导致性能欠佳。与这些工作不同，我们 GCA  中使用的拓扑和属性级别的自适应数据增强能够通过随机扰动保留图底层 的重要模式。</p>
<p><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/05/30/24bddc93cacbd1f703e1228984a3feab-image-20220530211332979-bd6dd3.png" alt="image-20220530211332979"></p>
<h2 id="3-THE-PROPOSED-METHOD">3 THE PROPOSED METHOD</h2>
<h3 id="3-1-Preliminaries">3.1 Preliminaries</h3>
<h3 id="3-2-The-Contrastive-Learning-Framework">3.2 The Contrastive Learning Framework</h3>
<p>图对比学习框架遵循通用图 CL 范式，其中模型寻求最大化不同视图之间表示内的一致性。具体来说，我们首先通过对输入执行随机图增强来生成两个图视图。然后，我们采用对比目标，强制两个不同视图中每个节点的编码嵌入彼此一致，并且可以与其他节点的嵌入区分开来。</p>
<p>具体的，每次迭代，采样两个随机的增强函数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>∼</mo><mi mathvariant="script">T</mi></mrow><annotation encoding="application/x-tex">t \sim \mathcal{T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.25417em;">T</span></span></span></span> 和  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>t</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>∼</mo><mi mathvariant="script">T</mi></mrow><annotation encoding="application/x-tex">t&#x27; \sim \mathcal T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.25417em;">T</span></span></span></span> ，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">T</mi></mrow><annotation encoding="application/x-tex">\mathcal T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.25417em;">T</span></span></span></span> 是所有可能的增强函数的集合。产生了两个增强视图 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>G</mi><mo stretchy="true">~</mo></mover><mn>1</mn></msub><mo>=</mo><mi>t</mi><mo stretchy="false">(</mo><mi>G</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\widetilde G_1 = t(G)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0933em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9433em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">G</span></span><span class="svg-align" style="width:calc(100% - 0.1667em);margin-left:0.1667em;top:-3.6833em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.26em;"><svg xmlns="http://www.w3.org/2000/svg" width='100%' height='0.26em' viewBox='0 0 600 260' preserveAspectRatio='none'><path d='M200 55.538c-77 0-168 73.953-177 73.953-3 0-7
-2.175-9-5.437L2 97c-1-2-2-4-2-6 0-4 2-7 5-9l20-12C116 12 171 0 207 0c86 0
 114 68 191 68 78 0 168-68 177-68 4 0 7 2 9 5l12 19c1 2.175 2 4.35 2 6.525 0
 4.35-2 7.613-5 9.788l-19 13.05c-92 63.077-116.937 75.308-183 76.128
-68.267.847-113-73.952-191-73.952z'/></svg></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal">G</span><span class="mclose">)</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>G</mi><mo stretchy="true">~</mo></mover><mn>2</mn></msub><mo>=</mo><mi>t</mi><mo stretchy="false">(</mo><mi>G</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\widetilde G_2 = t(G)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0933em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9433em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">G</span></span><span class="svg-align" style="width:calc(100% - 0.1667em);margin-left:0.1667em;top:-3.6833em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.26em;"><svg xmlns="http://www.w3.org/2000/svg" width='100%' height='0.26em' viewBox='0 0 600 260' preserveAspectRatio='none'><path d='M200 55.538c-77 0-168 73.953-177 73.953-3 0-7
-2.175-9-5.437L2 97c-1-2-2-4-2-6 0-4 2-7 5-9l20-12C116 12 171 0 207 0c86 0
 114 68 191 68 78 0 168-68 177-68 4 0 7 2 9 5l12 19c1 2.175 2 4.35 2 6.525 0
 4.35-2 7.613-5 9.788l-19 13.05c-92 63.077-116.937 75.308-183 76.128
-68.267.847-113-73.952-191-73.952z'/></svg></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal">G</span><span class="mclose">)</span></span></span></span> ，两个视图分别得到的节点嵌入是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mover accent="true"><mi>X</mi><mo stretchy="true">~</mo></mover><mn>1</mn></msub><mo separator="true">,</mo><msub><mover accent="true"><mi>A</mi><mo stretchy="true">~</mo></mover><mn>1</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">U=f(\widetilde X_1, \widetilde A_1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1933em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9433em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span><span class="svg-align" style="width:calc(100% - 0.1667em);margin-left:0.1667em;top:-3.6833em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.26em;"><svg xmlns="http://www.w3.org/2000/svg" width='100%' height='0.26em' viewBox='0 0 600 260' preserveAspectRatio='none'><path d='M200 55.538c-77 0-168 73.953-177 73.953-3 0-7
-2.175-9-5.437L2 97c-1-2-2-4-2-6 0-4 2-7 5-9l20-12C116 12 171 0 207 0c86 0
 114 68 191 68 78 0 168-68 177-68 4 0 7 2 9 5l12 19c1 2.175 2 4.35 2 6.525 0
 4.35-2 7.613-5 9.788l-19 13.05c-92 63.077-116.937 75.308-183 76.128
-68.267.847-113-73.952-191-73.952z'/></svg></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9433em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span class="svg-align" style="width:calc(100% - 0.2778em);margin-left:0.2778em;top:-3.6833em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.26em;"><svg xmlns="http://www.w3.org/2000/svg" width='100%' height='0.26em' viewBox='0 0 600 260' preserveAspectRatio='none'><path d='M200 55.538c-77 0-168 73.953-177 73.953-3 0-7
-2.175-9-5.437L2 97c-1-2-2-4-2-6 0-4 2-7 5-9l20-12C116 12 171 0 207 0c86 0
 114 68 191 68 78 0 168-68 177-68 4 0 7 2 9 5l12 19c1 2.175 2 4.35 2 6.525 0
 4.35-2 7.613-5 9.788l-19 13.05c-92 63.077-116.937 75.308-183 76.128
-68.267.847-113-73.952-191-73.952z'/></svg></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mover accent="true"><mi>X</mi><mo stretchy="true">~</mo></mover><mn>2</mn></msub><mo separator="true">,</mo><msub><mover accent="true"><mi>A</mi><mo stretchy="true">~</mo></mover><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">V=f(\widetilde X_2, \widetilde A_2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1933em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9433em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span><span class="svg-align" style="width:calc(100% - 0.1667em);margin-left:0.1667em;top:-3.6833em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.26em;"><svg xmlns="http://www.w3.org/2000/svg" width='100%' height='0.26em' viewBox='0 0 600 260' preserveAspectRatio='none'><path d='M200 55.538c-77 0-168 73.953-177 73.953-3 0-7
-2.175-9-5.437L2 97c-1-2-2-4-2-6 0-4 2-7 5-9l20-12C116 12 171 0 207 0c86 0
 114 68 191 68 78 0 168-68 177-68 4 0 7 2 9 5l12 19c1 2.175 2 4.35 2 6.525 0
 4.35-2 7.613-5 9.788l-19 13.05c-92 63.077-116.937 75.308-183 76.128
-68.267.847-113-73.952-191-73.952z'/></svg></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9433em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span class="svg-align" style="width:calc(100% - 0.2778em);margin-left:0.2778em;top:-3.6833em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.26em;"><svg xmlns="http://www.w3.org/2000/svg" width='100%' height='0.26em' viewBox='0 0 600 260' preserveAspectRatio='none'><path d='M200 55.538c-77 0-168 73.953-177 73.953-3 0-7
-2.175-9-5.437L2 97c-1-2-2-4-2-6 0-4 2-7 5-9l20-12C116 12 171 0 207 0c86 0
 114 68 191 68 78 0 168-68 177-68 4 0 7 2 9 5l12 19c1 2.175 2 4.35 2 6.525 0
 4.35-2 7.613-5 9.788l-19 13.05c-92 63.077-116.937 75.308-183 76.128
-68.267.847-113-73.952-191-73.952z'/></svg></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 。</p>
<p>之后，我们采用对比目标，即鉴别器，将这两个不同视图中同一节点的嵌入与其他节点嵌入区分开来。对于任意一个节点，其在一个视图中生成的embedding，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">u_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，被视为anchor，它在另一个视图中生成的embedding，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">v_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，形成正样本，两个视图中的其他embeddings自然被视为负样本样品。在我们的多视图图对比学习设置中模仿了 InfoNCE 目标 [42]，我们将每个正对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(u,v)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mclose">)</span></span></span></span> 的成对目标定义为:</p>
<p><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/05/30/a869738db0228b8b229850399e10308d-image-20220530215456203-727721.png" alt="image-20220530215456203"></p>
<p>然后将要最大化的总体目标定义为所有正对的平均值，正式由下式给出:</p>
<p><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/05/30/57c7207aedf926045ed6fcad268d5681-image-20220530222716113-2c7b52.png" alt="image-20220530222716113"></p>
<p><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/05/30/0b538df3f9f79667ab833ae4b74b663d-image-20220530222805399-3d5dce.png" alt="image-20220530222805399"></p>
<h3 id="3-3-Adaptive-Graph-Augmentation">3.3 Adaptive Graph Augmentation</h3>
<p>本质上，最大化视图之间一致性的对比学习方法寻求学习对增强方案引入的扰动不变的表示。在模型中，我们建议设计增强方案，这些方案倾向于保持重要结构和属性不变，同时扰乱可能不重要的链接和特征。具体来说，我们通过随机删除图中的边和屏蔽节点特征来破坏输入图，并且对于不重要的边或特征，删除或屏蔽的概率是倾斜的，即不重要的边或特征较高，重要的边或特征较低。</p>
<p>从摊销的角度来看，我们在随机损坏的视图上强调重要的结构和属性，这指导模型保留基本的拓扑和语义图模式。</p>
<h4 id="3-3-1-Topology-level-augmentation">3.3.1 Topology-level augmentation</h4>
<p>对于拓扑级别的增强，我们考虑了一种破坏输入图的直接方法，其中我们随机删除图中的边。形式上，我们以概率从原始 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ε</mi></mrow><annotation encoding="application/x-tex">\varepsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ε</span></span></span></span> 中采样一个修改的子集 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>ε</mi><mo stretchy="true">~</mo></mover></mrow><annotation encoding="application/x-tex">\widetilde \varepsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6906em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6906em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">ε</span></span><span class="svg-align" style="width:calc(100% - 0.1667em);margin-left:0.1667em;top:-3.4306em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.26em;"><svg xmlns="http://www.w3.org/2000/svg" width='100%' height='0.26em' viewBox='0 0 600 260' preserveAspectRatio='none'><path d='M200 55.538c-77 0-168 73.953-177 73.953-3 0-7
-2.175-9-5.437L2 97c-1-2-2-4-2-6 0-4 2-7 5-9l20-12C116 12 171 0 207 0c86 0
 114 68 191 68 78 0 168-68 177-68 4 0 7 2 9 5l12 19c1 2.175 2 4.35 2 6.525 0
 4.35-2 7.613-5 9.788l-19 13.05c-92 63.077-116.937 75.308-183 76.128
-68.267.847-113-73.952-191-73.952z'/></svg></span></span></span></span></span></span></span></span></span> 。</p>
<p><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/05/30/4d405fab761a72aba116b9672b90a177-image-20220530225613641-1cf64a.png" alt="image-20220530225613641"></p>
<p>这里的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>p</mi><mrow><mi>u</mi><mi>v</mi></mrow><mi>e</mi></msubsup></mrow><annotation encoding="application/x-tex">p^e_{uv}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9114em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">uv</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span> 代表了边 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(u,v)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mclose">)</span></span></span></span> 的重要程度。这样增强函数更有可能破坏不重要的边缘，同时在增强视图中保持重要的连接结构完整。</p>
<p>在网络科学中，节点中心性是一种广泛使用的度量，用于量化图中节点的影响。我们为边 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(u,v)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mclose">)</span></span></span></span> 定义边中心性 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>w</mi><mrow><mi>u</mi><mi>v</mi></mrow><mi>e</mi></msubsup></mrow><annotation encoding="application/x-tex">w^e_{uv}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9114em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-2.453em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">uv</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span> ，以根据两个连接节点的中心性来衡量其影响。给定节点中心度度量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>φ</mi><mo stretchy="false">(</mo><mo separator="true">⋅</mo><mo stretchy="false">)</mo><mo>:</mo><mi mathvariant="script">V</mi><mo>→</mo><msup><mi mathvariant="double-struck">R</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">\varphi(·):\mathcal V→ \mathbb R^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">φ</span><span class="mopen">(</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.08222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7713em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span>，我们将边中心度定义为两个相邻节点中心度的平均值, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>w</mi><mrow><mi>u</mi><mi>v</mi></mrow><mi>e</mi></msubsup><mo>=</mo><mo stretchy="false">(</mo><msub><mi>φ</mi><mi>c</mi></msub><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>+</mo><msub><mi>φ</mi><mi>c</mi></msub><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">w_{uv}^e = (\varphi_c(u) + \varphi_c(v))/2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9114em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-2.453em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">uv</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">φ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">φ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mclose">))</span><span class="mord">/2</span></span></span></span> ，针对有向图，边的重要程度使用尾结点的中心度表示，因为边缘的重要性通常由它们指向的节点来表征。</p>
<p>利用中心性计算每个边的概率，由于像度这样的节点中心性值可能会在数量级上有所不同，所以先取一下log，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>s</mi><mrow><mi>u</mi><mi>v</mi></mrow><mi>e</mi></msubsup><mo>=</mo><mi>log</mi><mo>⁡</mo><msubsup><mi>w</mi><mrow><mi>u</mi><mi>v</mi></mrow><mi>e</mi></msubsup></mrow><annotation encoding="application/x-tex">s^e_{uv}=\log w^e_{uv}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9114em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">uv</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9414em;vertical-align:-0.247em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-2.453em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">uv</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span> ，以减轻具有高度密集连接的节点的影响。</p>
<p><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/05/31/784abb8ada15588471ba1ddb6a0bdd60-image-20220531190239074-cd4fbd.png" alt="image-20220531190239074"></p>
<p>对于节点中心性函数的选择，我们使用以下三个中心性度量，包括度中心性、特征向量中心性和 PageRank 中心性，因为它们简单有效。</p>
<p><strong>Degree centrality.</strong> 节点度本身可以是一个中心性度量。在有向网络上，我们使用入度，因为有向图中节点的影响主要由指向它的节点赋予。尽管节点度是最简单的中心度度量之一，但它非常有效且具有启发性。</p>
<p><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/08/01/974a971ced9cf412773747de445d47cb-image-20220801161249853-899c2e.png" alt="image-20220801161249853"></p>
<p><strong>Eigenvector centrality.</strong> 节点的特征向量中心性计算为其特征向量对应于邻接矩阵的最大特征值。不同于度中心性假设所有邻居节点的重要性贡献相等，特征向量中心性还考虑了邻居节点的重要性。</p>
<p>根据定义，每个节点的特征向量中心性与其邻居的中心性之和成正比，连接多个邻居的节点或连接有影响力的节点都会有高的特征向量中心性值。</p>
<p>在有向图上，我们使用正确的特征向量来计算中心性，这对应于进入边。注意，由于只需要第一特征向量，计算特征向量中心性的计算负担可以忽略不计。</p>
<p><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/08/01/3a208321d943bff8f6f1fdcd0559b2fc-image-20220801165133526-04c57e.png" alt="image-20220801165133526"></p>
<p><strong>PageRank centrality.</strong></p>
<p>PageRank中心性定义为PageRank算法计算的PageRank权重。该算法沿有向边传播影响，将聚集影响最多的节点视为重要节点。形式上，中心性值由</p>
<p><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/08/01/f51561e45958897e2e4d5f474d9a40a3-image-20220801204848957-70ac12.png" alt="image-20220801204848957"></p>
<p>对于无向图，我们对变换后的有向图执行PageRank，其中每个无向边被转换为两个有向边。</p>
<p>为了直观地了解这些自适应结构增强方案，我们计算了著名空手道俱乐部数据集[50]的边缘中心性得分，该数据集包含两个教练分别带领的两组学生。不同方案计算的边缘中心性值如图2所示。从图中可以看出，虽然三种方案存在细微的差异，但所有的增强方案都倾向于强调两组内部连接两个教练(红色部分)的边，而较少关注跨组的外围节点之间的联系，这验证了所提出的基于节点中心的自适应拓扑增广方案能够识别图的基本结构。</p>
<p>通过空手道俱乐部数据集中的三种方案计算的边缘中心性的可视化，中心性值以边缘的厚度表示。节点颜色表示网络内部的两个类;两个教练是红色的。</p>
<h4 id="3-3-2-Node-attribute-level-augmentation">3.3.2 Node-attribute-level augmentation</h4>
<p>在节点属性层面，类似于计算机视觉中的椒盐噪声，我们通过在节点特征中随机屏蔽部分维数为零来为节点属性添加噪声。形式上，我们首先抽取一个随机向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>m</mi><mo stretchy="true">~</mo></mover><mo>∈</mo><mo stretchy="false">{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><msup><mo stretchy="false">}</mo><mi>F</mi></msup></mrow><annotation encoding="application/x-tex">\widetilde m \in \{0, 1\}^F</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7297em;vertical-align:-0.0391em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6906em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">m</span></span><span class="svg-align" style="top:-3.4306em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.26em;"><svg xmlns="http://www.w3.org/2000/svg" width='100%' height='0.26em' viewBox='0 0 600 260' preserveAspectRatio='none'><path d='M200 55.538c-77 0-168 73.953-177 73.953-3 0-7
-2.175-9-5.437L2 97c-1-2-2-4-2-6 0-4 2-7 5-9l20-12C116 12 171 0 207 0c86 0
 114 68 191 68 78 0 168-68 177-68 4 0 7 2 9 5l12 19c1 2.175 2 4.35 2 6.525 0
 4.35-2 7.613-5 9.788l-19 13.05c-92 63.077-116.937 75.308-183 76.128
-68.267.847-113-73.952-191-73.952z'/></svg></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">F</span></span></span></span></span></span></span></span></span></span></span> 也就是说 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>m</mi><mo stretchy="true">~</mo></mover></mrow><annotation encoding="application/x-tex">\widetilde m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6906em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6906em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">m</span></span><span class="svg-align" style="top:-3.4306em;"><span class="pstrut" style="height:3em;"></span><span style="height:0.26em;"><svg xmlns="http://www.w3.org/2000/svg" width='100%' height='0.26em' viewBox='0 0 600 260' preserveAspectRatio='none'><path d='M200 55.538c-77 0-168 73.953-177 73.953-3 0-7
-2.175-9-5.437L2 97c-1-2-2-4-2-6 0-4 2-7 5-9l20-12C116 12 171 0 207 0c86 0
 114 68 191 68 78 0 168-68 177-68 4 0 7 2 9 5l12 19c1 2.175 2 4.35 2 6.525 0
 4.35-2 7.613-5 9.788l-19 13.05c-92 63.077-116.937 75.308-183 76.128
-68.267.847-113-73.952-191-73.952z'/></svg></span></span></span></span></span></span></span></span></span> 每个元素只能是0 or 1，它的每个维度都独立地来自伯努利分布。注意，对于伯努利分布，每个维度都有不同的概率。</p>
<p><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/08/02/c0abe3ecad424bf53e0395afba5a4850-image-20220802085451172-f55aca.png" alt="image-20220802085451172"></p>
<p>与拓扑级增强相似，概率 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>p</mi><mi>i</mi><mi>f</mi></msubsup></mrow><annotation encoding="application/x-tex">p_i^f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2439em;vertical-align:-0.2769em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.967em;"><span style="top:-2.4231em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.1809em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2769em;"><span></span></span></span></span></span></span></span></span></span> 应该反映节点特征的第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 维的重要性。我们假设在影响节点中频繁出现的特征维度是重要的，并定义特征维度的权重如下。</p>
<p><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/08/02/e1da4d1a19f2ed8f78fc86cd1c55e873-image-20220802085349829-7deb29.png" alt="image-20220802085349829"></p>
<p>我们假设在影响节点中频繁出现的特征维度是重要的，并定义特征维度的权重如上，也就是说把所有节点的某一个维度的特征全部加起来，如果大，那么这个维度的特征就是重要的。</p>
<p>按照类似的拓扑增宽步骤，我们对权重进行归一化操作，以获得最终的概率。在形式上,</p>
<p><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/08/04/20bf6becf1c02cfd66bd3e60f5553d4b-image-20220804084451037-ec875f.png" alt="image-20220804084451037"></p>
<p>最后生成两个增强图，其中主要是改变了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>e</mi></msub><mo separator="true">,</mo><msub><mi>p</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">p_e, p_f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 生成两个不同的增强图。</p>
<p>注意，在GCA中使用的所有中心性和权重度量只依赖于内在拓扑和节点属性。因此，它们只需要计算一次，不会带来太大的计算负担。</p>
<h2 id="4-EXPERIMENTS">4 EXPERIMENTS</h2>
<p>RQ1。我们提出的GCA在节点分类任务中是否优于现有的基线方法?</p>
<p>RQ2。所有提出的自适应图增长方案都有利于模型的学习吗?每个图增加方案如何影响模型性能?</p>
<p>RQ3。提出的模型对超参数敏感吗?关键超参数如何影响模型性能?</p>
<h3 id="4-1-Experimental-Setup">4.1 Experimental Setup</h3>
<ul>
<li><strong>Wiki-CS</strong></li>
</ul>
<p>是一个从维基百科构建的参考网络。节点对应于关于计算机科学的文章，而边是文章之间的超链接。节点用10(10)个类标记，每个类代表字段的一个分支。节点特征计算为每篇文章中单词预训练的GloVe[31]单词嵌入的平均值。</p>
<ul>
<li><strong>Amazon-Computers and Amazon-Photo</strong></li>
</ul>
<p>是两个合作购买关系网络。它们是根据亚马逊的共同购买图构建的，其中节点是商品，当两个商品经常一起购买时，它们是连接在一起的。每个节点都有一个稀疏的词袋特征来编码产品评论，并用它的类别来标记。</p>
<ul>
<li><strong>Coauthor-CS and Coauthor-Physic</strong></li>
</ul>
<p>是两个合著者网络，其中包含基于2016年KDD杯挑战赛微软学术图的合著者图表。在这些图中，节点表示作者，边表示合著关系;也就是说，如果两个节点参与了一篇论文的合著，那么两个节点是连接在一起的。每个节点都有一个基于作者论文关键词的稀疏词袋特征。节点标签是作者最活跃的研究领域。</p>
<h4 id="4-1-2-Evaluation-protocol">4.1.2 Evaluation protocol</h4>
<p>对于每个实验，我们遵循Veličković等[44]中引入的线性评估方案，其中每个模型首先以无监督的方式进行训练;然后，将得到的嵌入用于训练和测试一个简单的ℓ2-正则化逻辑回归分类器。</p>
<p>我们针对不同的数据分割对模型进行了20次(20次)的训练，并报告每个数据集上的平均性能以获得公平的评估。此外，我们在这些实验中以分类精度来衡量性能。</p>
<h4 id="4-1-3-Baselines">4.1.3 Baselines</h4>
<p>此外，我们报告了在原始节点特征上使用逻辑回归分类器以及将嵌入与输入节点特征连接起来的DeepWalk获得的性能。为了直接将我们提出的方法与有监督的方法进行比较，我们还报告了两种代表性模型的性能:图卷积网络(GCN)[22]和图注意网络(GAT)[43]，它们以端到端方式进行训练。对于所有的基线，我们都根据它们的官方代码报告它们的性能。</p>
<h3 id="4-2-Performance-on-Node-Classification-RQ1">4.2 Performance on Node Classification (RQ1)</h3>
<p>实证绩效如表3所示。总的来说，从表中我们可以看到，我们提出的模型在所有5个数据集上都表现出了很强的性能。在这两种转导任务上，GCA始终比无监督基线表现得更好。较强的性能验证了所提出的对比学习框架的优越性。在两个Coauthor数据集上，我们注意到现有的基线已经获得了足够高的性能;我们的GCA方法仍然向前推进。此外，我们特别注意到，GCA与在所有5个数据集上使用标签监督训练的模型是有竞争力的。</p>
<p>我们提出的其他意见如下。首先，传统的对比学习方法如DeepWalk的性能不如简单的逻辑回归分类器(Coauthor-CS和Coauthor-Physics)，后者只使用一些数据集上的原始特征，这表明这些方法在利用节点特征方面可能是低效的。与传统工作不同，我们看到基于gcn的方法，例如GAE，能够在学习时结合节点特性。</p>
<p>我们提出的其他意见如下。首先，传统的对比学习方法如DeepWalk的性能不如简单的逻辑回归分类器(Coauthor-CS和Coauthor-Physics)，后者只使用一些数据集上的原始特征，这表明这些方法在利用节点特征方面可能是低效的。与传统工作不同，我们看到基于gcn的方法，例如GAE，能够在学习时结合节点特性。然而，我们注意到，在某些数据集(Wiki-CS)上，它们的性能仍然比DeepWalk +特性差，我们认为这可以归因于他们的naïve方法选择负样本，简单地选择基于边缘的对比对。 **这一事实进一步证明了基于增强图视图选择负样本在对比表示学习中的重要作用。**此外，与现有的基线DGI、GMI和MVGRL相比，我们提出的方法表现出强大的自适应数据增强构造负样本，导致更好的性能。需要注意的是，虽然MVGRL采用扩散的方法将全局信息纳入到增强视图中，但它仍然不能自适应地考虑不同边对输入图的影响。GCA的优越性能验证了我们提出的自适应数据增强方案能够通过在扰动过程中保留重要的模式来帮助提高嵌入质量。</p>
<p>其次，我们观察到具有不同节点中心性度量的GCA的所有三个变量在所有数据集上都优于现有的对比基线。我们还注意到，分别具有程度和PageRank中心性的GCA-DE和GCA-PR是两个强大的变体，它们在所有数据集上取得了最好的或竞争性的性能。请注意，结果表明我们的模型不局限于中心性措施的具体选择，并验证了我们提出的框架的有效性和一般性。</p>
<p><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/08/04/aa0b2300910369c6f4720ec265ef649b-image-20220804113032883-56b93a.png" alt="image-20220804113032883"></p>
<h3 id="4-3-Ablation-Studies-RQ2">4.3 Ablation Studies (RQ2)</h3>
<p>在本节中，我们将提出的拓扑和属性级别增强替换为它们的统一对应项，以研究GCA每个组件的影响。GCA-T-A表示具有统一拓扑和节点属性级增强方案的模型，其中所有节点的下降边和掩蔽特征的概率设置为相同。变量GCA-T和GCA-A的定义类似，只是我们分别用<strong>统一抽样替换拓扑和节点属性增强方案</strong>。度中心性用于所有变体的公平比较。</p>
<p><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/08/04/5f90d6af21c6890b04cf64716d83dc02-image-20220804113047268-9f624a.png" alt="image-20220804113047268"></p>
<h3 id="4-4-Sensitivity-Analysis-RQ3">4.4 Sensitivity Analysis (RQ3)</h3>
<p>在本节中，我们对GCA中的关键超参数进行灵敏度分析，即决定图视图生成的四种概率 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi>e</mi><mo separator="true">,</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>p</mi><mrow><mi>e</mi><mo separator="true">,</mo><mn>2</mn></mrow></msub><mo separator="true">,</mo><msub><mi>p</mi><mrow><mi>f</mi><mo separator="true">,</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>p</mi><mrow><mi>f</mi><mo separator="true">,</mo><mn>2</mn></mrow></msub></mrow><annotation encoding="application/x-tex">p_{e,1}, p_{e,2}, p_{f,1}, p_{f,2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> ，以显示模型在这些超参数扰动下的稳定性。注意，我们在灵敏度分析中只改变这四个参数，其他参数与前面描述的相同。</p>
<p><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/08/04/9edf79faf7f6303bd2a69f18d37cd098-image-20220804113751220-f10457.png" alt="image-20220804113751220"></p>
<p>Amazon-Photo数据集上的结果如图3所示。从图中可以看出，当参数不太大时，节点分类的精度表现相对稳定，如图中的平台所示。因此，我们得出结论，总体上，我们的模型对这些概率不敏感，证明了超参数调优的鲁棒性</p>
<p>如果概率设置得太大(例如&gt; 0.5)，原始图将严重受损。例如，当<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>e</mi></msub><mo>=</mo><mn>0.9</mn></mrow><annotation encoding="application/x-tex">p_e = 0.9</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.9</span></span></span></span>时，几乎所有现有的边都被删除，导致生成的图视图中孤立的节点。那么，在这种情况下，图卷积网络很难从节点邻域学习到有用的信息。因此，学习到的两个图视图中的节点嵌入不够鲜明，导致对比目标难以优化。</p>
<h2 id="5-CONCLUSION">5 CONCLUSION</h2>
<p>在本文中，我们开发了一种新的具有自适应增强的图对比表示学习框架。我们的模型通过最大化自适应图增强生成的视图之间的节点嵌入的一致性来学习表示。提出的自适应增强算法首先通过中心性度量确定重要边缘和特征维数。</p>
<p>然后，在拓扑层面，我们通过在不重要的边上分配大概率随机移除边，以强制模型识别重要的连接结构。在节点属性级别，我们通过向不重要的特征维度添加更多噪声来破坏属性，以强调底层语义信息。我们使用各种真实世界的数据集进行了全面的实验。实验结果表明，我们提出的方法始终优于现有的最先进的方法，甚至超过几个监督的同行。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:1941686805@qq.com">Wangzhiqiang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2022/06/29/Paper-[WWW%2021]%20Graph%20Contrastive%20Learning%20with%20Adaptive%20Augmentation/">http://example.com/2022/06/29/Paper-[WWW%2021]%20Graph%20Contrastive%20Learning%20with%20Adaptive%20Augmentation/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">hahahaha哈士奇</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">对比学习</a><a class="post-meta__tags" href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3/">无监督</a></div><div class="post_share"><div class="social-share" data-image="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/b36a188093daf2e64a217a84bf183201-nKO_1QyFh9o-2edcfd.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/e10b5ee4c740dbc358231b386ec0ce88-image-20220320190054218-938bb2.png" target="_blank"><img class="post-qr-code-img" src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/e10b5ee4c740dbc358231b386ec0ce88-image-20220320190054218-938bb2.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/2f304c57c620209d44ba0b66e099c092-image-20220320190039458-2fb3a9.png" target="_blank"><img class="post-qr-code-img" src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/2f304c57c620209d44ba0b66e099c092-image-20220320190039458-2fb3a9.png" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/06/29/Paper-%5BWWW%2022%5D-SimGRACEA%20Simple%20Framework%20for%20Graph%20Contrastive%20Learning%20without%20Data%20Augmentation/"><img class="prev-cover" src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/b36a188093daf2e64a217a84bf183201-nKO_1QyFh9o-2edcfd.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Paper-[WWW 22]-SimGRACEA Simple Framework for Graph Contrastive Learning without Data Augmentation</div></div></a></div><div class="next-post pull-right"><a href="/2022/06/29/Paper-%5BPMLR-20%5D-MVGRL-Contrastive-Multi-View-Representation-Learning-on-Graphs/"><img class="next-cover" src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/b36a188093daf2e64a217a84bf183201-nKO_1QyFh9o-2edcfd.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Paper-[PMLR 20]-Contrastive Multi-View Representation Learning on Graphs</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/06/29/Paper-%5BICLR%202019%5D-Deep-Graph-Infomax/" title="Paper-[ICLR 2019]-Deep-Graph-Infomax"><img class="cover" src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/b36a188093daf2e64a217a84bf183201-nKO_1QyFh9o-2edcfd.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-29</div><div class="title">Paper-[ICLR 2019]-Deep-Graph-Infomax</div></div></a></div><div><a href="/2022/06/29/Paper-%5BICML%202020%5D-A-Simple-Framework-for-Contrastive-Learning-of-Visual-Representations/" title="Paper-[ICML 2020]SimCLR A Simple Framework for Contrastive Learning of Visual Representations"><img class="cover" src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/b36a188093daf2e64a217a84bf183201-nKO_1QyFh9o-2edcfd.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-29</div><div class="title">Paper-[ICML 2020]SimCLR A Simple Framework for Contrastive Learning of Visual Representations</div></div></a></div><div><a href="/2022/07/01/Paper-%5BJMLR%2020%5D-A%20Simple%20Framework%20for%20Contrastive%20Learning%20of%20Visual%20Representations/" title="Paper-[JMLR 20]-A Simple Framework for Contrastive Learning of Visual Representations"><img class="cover" src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/b36a188093daf2e64a217a84bf183201-nKO_1QyFh9o-2edcfd.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-07-01</div><div class="title">Paper-[JMLR 20]-A Simple Framework for Contrastive Learning of Visual Representations</div></div></a></div><div><a href="/2022/06/29/Paper-%5BWWW%2022%5D-SimGRACEA%20Simple%20Framework%20for%20Graph%20Contrastive%20Learning%20without%20Data%20Augmentation/" title="Paper-[WWW 22]-SimGRACEA Simple Framework for Graph Contrastive Learning without Data Augmentation"><img class="cover" src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/b36a188093daf2e64a217a84bf183201-nKO_1QyFh9o-2edcfd.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-29</div><div class="title">Paper-[WWW 22]-SimGRACEA Simple Framework for Graph Contrastive Learning without Data Augmentation</div></div></a></div><div><a href="/2022/06/29/Paper-%5BICLR%202020%5D-CONTRASTIVE%20REPRESENTATION%20DISTILLATION/" title="Paper-[ICLR 2020]-CONTRASTIVE REPRESENTATION DISTILLATION"><img class="cover" src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/b36a188093daf2e64a217a84bf183201-nKO_1QyFh9o-2edcfd.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-29</div><div class="title">Paper-[ICLR 2020]-CONTRASTIVE REPRESENTATION DISTILLATION</div></div></a></div><div><a href="/2022/06/29/Paper-%5BPMLR-20%5D-MVGRL-Contrastive-Multi-View-Representation-Learning-on-Graphs/" title="Paper-[PMLR 20]-Contrastive Multi-View Representation Learning on Graphs"><img class="cover" src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/b36a188093daf2e64a217a84bf183201-nKO_1QyFh9o-2edcfd.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-29</div><div class="title">Paper-[PMLR 20]-Contrastive Multi-View Representation Learning on Graphs</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="lv-container" data-id="city" data-uid="MTAyMC81NDcwMi8zMTE3Mw=="></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/1f2e377def5c6672de0cdeed4b54c36d-201672716495120191-a103ac.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Wangzhiqiang</div><div class="author-info__description">一只在路上的哈士奇</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">42</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">30</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">22</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/zhiqiang00"><i class="fab fa-github"></i><span>关注我吧~</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/zhiqiang00" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://leetcode-cn.com/u/wang-zhi-qiang-o/" target="_blank" title="LeetCode"><i class="fas fa-duotone fa-code"></i></a><a class="social-icon" href="https://blog.csdn.net/qq_43351000?type=blog" target="_blank" title="CSDN"><i class="iconfont icon-csdn1"></i></a><a class="social-icon" href="mailto:1941686805@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title=""><i class="rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">在这里记录自己学习的点点滴滴，希望和大家一起成长~欢迎分享交流哇！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Paper-Graph-Contrastive-Learning-with-Adaptive-Augmentation-www-21"><span class="toc-text">Paper-Graph Contrastive Learning with Adaptive Augmentation(www 21)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ABSTRACT"><span class="toc-text">ABSTRACT</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E4%BB%8B%E7%BB%8D"><span class="toc-text">1. 介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-RELATED-WORK"><span class="toc-text">2 RELATED WORK</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-Contrastive-Representation-Learning"><span class="toc-text">2.1 Contrastive Representation Learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-Graph-Representation-Learning"><span class="toc-text">2.2 Graph Representation Learning</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-THE-PROPOSED-METHOD"><span class="toc-text">3 THE PROPOSED METHOD</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-Preliminaries"><span class="toc-text">3.1 Preliminaries</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-The-Contrastive-Learning-Framework"><span class="toc-text">3.2 The Contrastive Learning Framework</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-Adaptive-Graph-Augmentation"><span class="toc-text">3.3 Adaptive Graph Augmentation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-1-Topology-level-augmentation"><span class="toc-text">3.3.1 Topology-level augmentation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-2-Node-attribute-level-augmentation"><span class="toc-text">3.3.2 Node-attribute-level augmentation</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-EXPERIMENTS"><span class="toc-text">4 EXPERIMENTS</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-Experimental-Setup"><span class="toc-text">4.1 Experimental Setup</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-2-Evaluation-protocol"><span class="toc-text">4.1.2 Evaluation protocol</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-3-Baselines"><span class="toc-text">4.1.3 Baselines</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-Performance-on-Node-Classification-RQ1"><span class="toc-text">4.2 Performance on Node Classification (RQ1)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-Ablation-Studies-RQ2"><span class="toc-text">4.3 Ablation Studies (RQ2)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-Sensitivity-Analysis-RQ3"><span class="toc-text">4.4 Sensitivity Analysis (RQ3)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-CONCLUSION"><span class="toc-text">5 CONCLUSION</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/08/04/Paper-%5BSIGIR%202022%5D-Knowledge%20Graph%20Contrastive%20Learning%20for%20Recommendation/" title="无题"><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/b36a188093daf2e64a217a84bf183201-nKO_1QyFh9o-2edcfd.jpg https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/7f0f94f3ea0db706c233c4bcb413c046-XfMeXNI42d8-b472ff.jpg https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/c2b838b9c0b8134dfcd60c63c78d286a-nTYkr4p6B9w-bd3b9b.jpg https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/e24723f0956f7819c9bf479295b501f7-RB7X0Q5te6s-86a933.jpg https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/330aa48b8c55d6422dfaa33caf494f01-tblFM8h5CN0-8d129d.jpg https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/08c72b270c54abbd8924e4c8888f7ee6-wFna77QtSi0-24c6d7.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="无题"/></a><div class="content"><a class="title" href="/2022/08/04/Paper-%5BSIGIR%202022%5D-Knowledge%20Graph%20Contrastive%20Learning%20for%20Recommendation/" title="无题">无题</a><time datetime="2022-08-04T09:19:23.033Z" title="发表于 2022-08-04 17:19:23">2022-08-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/07/02/Paper-%5BAAAI-21%5D-Augmentation-Free-Self-Supervised-Learning-on-Graphs/" title="Paper-[AAAI 21]-Augmentation-Free Self-Supervised Learning on Graphs"><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/b36a188093daf2e64a217a84bf183201-nKO_1QyFh9o-2edcfd.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Paper-[AAAI 21]-Augmentation-Free Self-Supervised Learning on Graphs"/></a><div class="content"><a class="title" href="/2022/07/02/Paper-%5BAAAI-21%5D-Augmentation-Free-Self-Supervised-Learning-on-Graphs/" title="Paper-[AAAI 21]-Augmentation-Free Self-Supervised Learning on Graphs">Paper-[AAAI 21]-Augmentation-Free Self-Supervised Learning on Graphs</a><time datetime="2022-07-02T06:51:39.731Z" title="发表于 2022-07-02 14:51:39">2022-07-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/07/01/Paper-%5BJMLR%2020%5D-A%20Simple%20Framework%20for%20Contrastive%20Learning%20of%20Visual%20Representations/" title="Paper-[JMLR 20]-A Simple Framework for Contrastive Learning of Visual Representations"><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/b36a188093daf2e64a217a84bf183201-nKO_1QyFh9o-2edcfd.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Paper-[JMLR 20]-A Simple Framework for Contrastive Learning of Visual Representations"/></a><div class="content"><a class="title" href="/2022/07/01/Paper-%5BJMLR%2020%5D-A%20Simple%20Framework%20for%20Contrastive%20Learning%20of%20Visual%20Representations/" title="Paper-[JMLR 20]-A Simple Framework for Contrastive Learning of Visual Representations">Paper-[JMLR 20]-A Simple Framework for Contrastive Learning of Visual Representations</a><time datetime="2022-07-01T02:18:33.778Z" title="发表于 2022-07-01 10:18:33">2022-07-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/07/01/Paper-%5BIEEE%2020%5D-Guardian-Evaluating%20Trust%20in%20Online%20Social%20Networks%20with%20Graph%20Convolutional%20Networks/" title="Paper-[IEEE 20]-Guardian-Evaluating Trust in Online Social Networks with Graph Convolutional Networks"><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/b36a188093daf2e64a217a84bf183201-nKO_1QyFh9o-2edcfd.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Paper-[IEEE 20]-Guardian-Evaluating Trust in Online Social Networks with Graph Convolutional Networks"/></a><div class="content"><a class="title" href="/2022/07/01/Paper-%5BIEEE%2020%5D-Guardian-Evaluating%20Trust%20in%20Online%20Social%20Networks%20with%20Graph%20Convolutional%20Networks/" title="Paper-[IEEE 20]-Guardian-Evaluating Trust in Online Social Networks with Graph Convolutional Networks">Paper-[IEEE 20]-Guardian-Evaluating Trust in Online Social Networks with Graph Convolutional Networks</a><time datetime="2022-07-01T02:18:33.766Z" title="发表于 2022-07-01 10:18:33">2022-07-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/07/01/Paper-%5BIEEE%2020%5D-AtNE-Trust%20Attributed%20Trust%20Network%20Embedding%20for%20Trust%20Prediction%20in%20Online%20Social%20Networks/" title="Paper-[IEEE 20]-AtNE-Trust Attributed Trust Network Embedding for Trust Prediction in Online Social Networks"><img src="https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/b36a188093daf2e64a217a84bf183201-nKO_1QyFh9o-2edcfd.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Paper-[IEEE 20]-AtNE-Trust Attributed Trust Network Embedding for Trust Prediction in Online Social Networks"/></a><div class="content"><a class="title" href="/2022/07/01/Paper-%5BIEEE%2020%5D-AtNE-Trust%20Attributed%20Trust%20Network%20Embedding%20for%20Trust%20Prediction%20in%20Online%20Social%20Networks/" title="Paper-[IEEE 20]-AtNE-Trust Attributed Trust Network Embedding for Trust Prediction in Online Social Networks">Paper-[IEEE 20]-AtNE-Trust Attributed Trust Network Embedding for Trust Prediction in Online Social Networks</a><time datetime="2022-07-01T02:18:33.748Z" title="发表于 2022-07-01 10:18:33">2022-07-01</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/9d2244833e878e2169062087c9ab0874-wallhaven-g72p87-af7e51.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2022 By Wangzhiqiang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">欢迎您的访问！</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Algolia</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script><script src="/js/search/algolia.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>function loadLivere () {
  if (typeof LivereTower === 'object') {
    window.LivereTower.init()
  }
  else {
    (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
    })(document, 'script');
  }
}

if ('Livere' === 'Livere' || !false) {
  if (false) btf.loadComment(document.getElementById('lv-container'), loadLivere)
  else loadLivere()
}
else {
  function loadOtherComment () {
    loadLivere()
  }
}</script></div><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script id="click-show-text" src="/%5Bobject%20Object%5D" data-mobile="false" data-text="I,LOVE,YOU" data-fontsize="17px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body></html>