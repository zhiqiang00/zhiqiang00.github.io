---
title: ML-机器学习评估方法
date: 2022年4月1日
categories: [机器学习]
tags: [评估方法]
katex: true
cover: https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/7f0f94f3ea0db706c233c4bcb413c046-XfMeXNI42d8-b472ff.jpg
top_img: https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/9d2244833e878e2169062087c9ab0874-wallhaven-g72p87-af7e51.jpg
---

##　机器学习评估方法

实验中，我们可能会通过实验对学习器的泛化误差进行评估然后选择好的学习器，这时使用**测试集**来测试学习器对新样本的判别能力。然后以测试集上的“测试误差”作为**泛化误差**的**近似**。

- 假设测试样本也是从样本真实分布中独立同分布采样而得
- 测试集应该尽可能与训练集互斥，这可以避免过拟合，提高模型的泛化能力

如果我们只有一个包含m个样例，纪要训练又要测试，则需要通过对数据适当进行处理，从中产生出训练集 $S$ 和测试集 $T$ 。有一下几种方法：

### 1. 留出法

指直接将数据集 $D$ 划分为两个互斥的集合，其中一个作为测试集 $S$ ，另一个作为训练集 $T$ 。

- 注意，划分要尽可能保持数据分布一致性，避免因为数据划分引入额外偏差。从采样的角度看待数据的划分过程，则**保留类别比例的采样方式**通常称为“分层采样”。
- 单次划分不稳定，一般采用多次随机划分、重复进行试验评估后取得平均值作为留出法的评估结果。
- 总样本数量固定，训练集大则模型更接近总训练集 $D$ ，但是这时候测试集会变小，评估结果不够稳定(测试集小，评估结果方差大)。如果令测试集数量增加，则训练集训练出来的学习器则与 $D$ 相差较大(训练集小，欧评估结果偏差大)。一般是**2/3 ~ 4/5**用于训练集。

### 2. 交叉验证法

指先将数据集划分为 $k$ 个大小相似的互斥子集，每子集尽可能保持数据一致性，即从 $D$ 中分层采样得到。每次使用 $k-1$ 个子集的并集作为训练集，剩余的那一个测试集作为测试集。从而可以进行 $k$ 次训练和测试。

进行10次10折交叉验证和100次留出法都是进行了100次训练。

**留一法：** 数据集 $D$ 中包含 $m$ 个样本，若令 $k=m$，那么就得到了一个交叉验证的特例：**留一法(Leave-One-Out)**。留一法使用的训练集与初始数据集相比只少了一个样本，这使得被实际评估的模型与期望评估的模型很相似。缺点是如果数据集比较大，那训练 $m$ 个模型的计算开销将会特别大。

### 3. 自助法

直接以自助采样法为基础，$D$ 中包含 $m$ 个数据，进行采样得到数据集 $D'$ ： 每次从 $D$ 中挑选一个样本，将其拷贝到 $D'$ 中，然后将这个样本放回到 $D$ 中，使得该样本下次应有机会被采集。这个过程重复 $m$ 次，就可以得到 $m$ 个样本数据集了。

其中，总会有一部分始终不被采集，不被采样的概率是 $(1 - \frac{1}{m})^m$ ，取极限得到：
$$
\lim_{m \to \infty} (1 - \frac{1}{m})^m = \frac{1}{e} \approx 0.368
$$
即通过自助法初始数据中约有36.8%的样本不在 $D'$ 中，于是 $D'$ 作为测试集， $D \textbackslash D'$ 用作测试集。

自助法在训练集较小的时候不好划分；这个方法产生多个不同的训练集，**这对集成学习方法有很大好处**。

缺陷：改变了初始数据集的分布，引入了偏差，因此数据充足时，留出法和交叉验证比较常用。

### 4. 调参与最终模型

一般参数是在整数范围内进行取值的，为了平衡计算开销和性能估计，一般在某个范围设定步长，然后选择几个数值去训练。

在模型选择后，学习算法和参数配置已选定，此时应该用初始数据集 $D$  重新训练模型，这是我们最终要提交的。

另外，我们通过把学得模型在实际中使用中遇见的数据称为**测试集**，为了加以区分，模型评估与选择中用于评估测试的数据集常称为**验证集**。

