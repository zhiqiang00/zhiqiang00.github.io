---
title: Paper-[www 21]-Graph Contrastive Learning with Adaptive Augmentation
tags: [对比学习, 无监督]
categories: [论文阅读]
katex: true
cover: https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/b36a188093daf2e64a217a84bf183201-nKO_1QyFh9o-2edcfd.jpg
top_img: https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/9d2244833e878e2169062087c9ab0874-wallhaven-g72p87-af7e51.jpg
---

## Paper-Graph Contrastive Learning with Adaptive Augmentation(www 21)



## ABSTRACT

对比学习已经成功应用在图无监督学习上，但是图增强方案的部分很关键但是很少被探索。作者**认为数据增强方案应该保留图的内在结构和属性信息，这将迫使模型学习对不重要节点和边上的扰动不敏感的表示。**然而，大多数现有方法采用统一的数据增强方案，如统一丢弃边缘和统一的打乱特征，导致性能欠佳。

本文提出了一种具有自适应增强的新型图对比表示学习方法，该方法结合了图的拓扑和语义方面的各种先验。

具体来说，在拓扑层面，我们设计了基于节点中心性度量的增强方案，以突出重要的连接结构。在节点属性级别，我们通过向不重要的节点特征添加更多噪声来破坏节点特征，强制模型识别底层语义信息。

## 1. 介绍

遵循着DGI，GMI 提出了两个节点级对比目标，以分别直接测量输入与节点和边的表示之间的 MI，而无需显式数据增强。

尽管图上的 CL 方法得到了蓬勃发展，但数据增强方案被证明是视觉表示学习的关键组成部分，但在现有文献中仍然很少探索。与可用于图像和文本的大量数据转换技术不同，在 CL 方法中定义图增强方案并非易事，因为由于非欧几里德属性，图要复杂得多。我们认为，上述方法中使用的增强方案有两个缺点。

- 首先，在结构域或属性域中进行简单的数据增强，例如 DGI 中的特征改变，不足以为节点生成不同的邻域（即上下文），特别是当节点特征稀疏时，导致难以优化对比目标。

- 其次，之前的工作在执行数据增强时忽略了节点和边影响的差异。如果我们通过均匀丢弃边来构建图视图，那么删除一些有影响的边会降低嵌入质量。数据增强策略应该适应输入图以反映其内在模式。

![image-20220526170508799](https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/05/26/31a44e382be26c194591d6e9da932101-image-20220526170508799-9ffd4e.png)

在 GCA 中，我们首先通过对输入执行随机损坏来生成两个相关的图视图。然后，我们使用对比损失来训练模型，以最大化这两个视图中节点嵌入之间的一致性。具体来说，我们提出了一种拓扑和节点属性级别的联合数据增强方案，即去除边缘和掩蔽特征，为不同视图的节点提供不同的上下文，从而促进对比目标的优化。

此外，我们通过中心性度量来识别重要的边缘和特征维度。然后，在拓扑级别上，我们通过对不重要的边缘给予较大的移除概率来自适应地丢弃边缘，以突出重要的连接结构。在节点属性级别，我们通过向不重要的特征维度添加更多噪声来破坏属性，以强制模型识别底层语义信息。

本文的核心贡献有两个，总结如下：

- 首先，我们提出了一个通用的对比框架，用于具有强大的自适应数据增强的无监督图表示学习。所提出的 GCA 框架在拓扑和属性级别上联合执行数据增强，以适应图结构和属性，这鼓励模型从两个方面学习重要特征。

- 其次，我们使用五个公共基准数据集在常用**的线性评估协议**下对节点分类进行了全面的实证研究。 GCA 始终优于现有方法，我们的无监督方法甚至在几个转换任务上超过了有监督的方法。

## 2 RELATED WORK

### 2.1 Contrastive Representation Learning

在自监督表示学习中很受欢迎，对比方法旨在通过对比正负样本来学习有区别的表示。

理论分析揭示了他们成功背后的原因。这些方法中使用的目标可以看作是最大化输入特征与其表示之间的 MI 下限。

然而，最近的工作表明，评估表示质量的下游性能可能在很大程度上取决于不仅在卷积架构中而且在 InfoMax 目标的特定估计器中编码的偏差。**也就是说，InfoMax的评估器很重要。**

### 2.2 Graph Representation Learning

许多传统的无监督图表示学习方法也采用对比范式

无监督表示学习之前的工作主要是吧先前的工作集中在局部对比模式上，这迫使邻居节点具有相似的嵌入。这种情况下的正样本是出现在同一个随机游走中的节点。例如，开创性工作 DeepWalk 使用噪声对比估计对节点共现对的概率进行建模。这些基于随机游走的方法被证明等价于分解某些形式的图邻近度。它过分强调在这些图形近似中编码的结构信息，并且还面临大规模数据集的严重缩放问题。此外，已知这些方法容易出错，并且超参数调整不当。

在 DGI 之后，GMI [30] 使用两个鉴别器直接测量输入与节点和边的表示之间的 MI，而无需数据增强； MVGRL [15]  提出通过执行节点扩散并将节点表示与增强的图摘要表示进行对比来学习节点级和图级表示。此外，GCC [34]  提出了一种基于对比学习的预训练框架。它提出通过基于随机游走对子图进行采样来构建多个图视图，然后使用多种特征工程方案学习模型权重

然而，这些方法没有明确考虑结构和属性级别的自适应图增强，导致性能欠佳。与这些工作不同，我们 GCA  中使用的拓扑和属性级别的自适应数据增强能够通过随机扰动保留图下方的重要模式。

![image-20220530211332979](https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/05/30/24bddc93cacbd1f703e1228984a3feab-image-20220530211332979-bd6dd3.png)

## 3 THE PROPOSED METHOD

### 3.1 Preliminaries

### 3.2 The Contrastive Learning Framework

图对比学习框架遵循通用图 CL 范式，其中模型寻求最大化不同视图之间表示内的一致性。具体来说，我们首先通过对输入执行随机图增强来生成两个图视图。然后，我们采用对比目标，强制两个不同视图中每个节点的编码嵌入彼此一致，并且可以与其他节点的嵌入区分开来。

具体的，每次迭代，采样两个随机的增强函数 $t \sim \mathcal{T}$ 和  $t' \sim \mathcal T$ ，其中 $\mathcal T$ 是所有可能的增强函数的集合。产生了两个增强视图 $\widetilde G_1 = t(G)$ 和 $\widetilde G_2 = t(G)$ ，两个视图分别得到的节点嵌入是 $U=f(\widetilde X_1, \widetilde A_1)$ 和 $V=f(\widetilde X_2, \widetilde A_2)$ 。

之后，我们采用对比目标，即鉴别器，将这两个不同视图中同一节点的嵌入与其他节点嵌入区分开来。对于任意一个节点푣푖，其在一个视图中生成的embedding，풖푖，被视为anchor，它在另一个视图中生成的embedding，풗푖，形成正样本，两个视图中的其他embeddings自然被视为负样本样品。在我们的多视图图对比学习设置中模仿了 InfoNCE 目标 [42]，我们将每个正对 $(u,v)$ 的成对目标定义为:

![image-20220530215456203](https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/05/30/a869738db0228b8b229850399e10308d-image-20220530215456203-727721.png)

然后将要最大化的总体目标定义为所有正对的平均值，正式由下式给出:

![image-20220530222716113](https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/05/30/57c7207aedf926045ed6fcad268d5681-image-20220530222716113-2c7b52.png)

![image-20220530222805399](https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/05/30/0b538df3f9f79667ab833ae4b74b663d-image-20220530222805399-3d5dce.png)

### 3.3 Adaptive Graph Augmentation

本质上，最大化视图之间一致性的对比学习方法寻求学习对增强方案引入的扰动不变的表示。在模型中，我们建议设计增强方案，这些方案倾向于保持重要结构和属性不变，同时扰乱可能不重要的链接和特征。具体来说，我们通过随机删除图中的边和屏蔽节点特征来破坏输入图，并且对于不重要的边或特征，删除或屏蔽的概率是倾斜的，即不重要的边或特征较高，重要的边或特征较低。

从摊销的角度来看，我们在随机损坏的视图上强调重要的结构和属性，这指导模型保留基本的拓扑和语义图模式。

#### 3.3.1 Topology-level augmentation

对于拓扑级别的增强，我们考虑了一种破坏输入图的直接方法，其中我们随机删除图中的边。形式上，我们以概率从原始 $\varepsilon$ 中采样一个修改的子集 $\widetilde \varepsilon$ 。

![image-20220530225613641](https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/05/30/4d405fab761a72aba116b9672b90a177-image-20220530225613641-1cf64a.png)

这里的 $p^e_{uv}$ 代表了边 $(u,v)$ 的重要程度。这样增强函数更有可能破坏不重要的边缘，同时在增强视图中保持重要的连接结构完整。

在网络科学中，节点中心性是一种广泛使用的度量，用于量化图中节点的影响。我们为边 $(u,v)$ 定义边中心性 $w^e_{uv}$ ，以根据两个连接节点的中心性来衡量其影响。给定节点中心度度量 $\varphi(·):\mathcal V→ \mathbb R^+$，我们将边中心度定义为两个相邻节点中心度的平均值, $w_{uv}^e = (\varphi_c(u) + \varphi_c(v))/2$ ，针对有向图，边的重要程度使用尾结点的中心度表示，因为边缘的重要性通常由它们指向的节点来表征。

利用中心性计算每个边的概率，由于像度这样的节点中心性值可能会在数量级上有所不同，所以先取一下log，$s^e_{uv}=\log w^e_{uv}$ ，以减轻具有高度密集连接的节点的影响。

![image-20220531190239074](https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/05/31/784abb8ada15588471ba1ddb6a0bdd60-image-20220531190239074-cd4fbd.png)

对于节点中心性函数的选择，我们使用以下三个中心性度量，包括度中心性、特征向量中心性和 PageRank 中心性，因为它们简单有效。

**Degree centrality.** 节点度本身可以是一个中心性度量。在有向网络上，我们使用入度，因为有向图中节点的影响主要由指向它的节点赋予。尽管节点度是最简单的中心度度量之一，但它非常有效且具有启发性。

**Eigenvector centrality.** 节点的特征向量中心性计算为其特征向量对应于邻接矩阵的最大特征值。

**PageRank centrality.** 



#### 3.3.2 Node-attribute-level augmentation



