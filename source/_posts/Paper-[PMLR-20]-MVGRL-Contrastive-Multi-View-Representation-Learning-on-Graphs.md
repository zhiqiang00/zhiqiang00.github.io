---
title: Paper-[PMLR 20]-Contrastive Multi-View Representation Learning on Graphs
tags: [对比学习]
categories: [论文阅读, PMLR]
katex: true
cover: https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/b36a188093daf2e64a217a84bf183201-nKO_1QyFh9o-2edcfd.jpg
top_img: https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/03/20/9d2244833e878e2169062087c9ab0874-wallhaven-g72p87-af7e51.jpg

---

## Paper Contrastive Multi-View Representation Learning on Graphs(PMLR20)

图上的对比多视图表示学习

## 摘要

文本通过对比图的结构视图提出一个节点和图级别的无监督表示学习方法。本文表明，与视觉表示学习，将视图数量增加到两个以上或对比多视图编码器不会提高性能，**而最佳性能是通过对比来自一阶邻居的编码和图扩散来实现的**。

## 1 Introduction

GNN 主要需要依赖于任务的标签来学习丰富的表示。标记图的成本很高，为了解决这个问题，诸如基于重构的方法和对比方法等无监督方法与GNN相结合，使它们能够在不依赖监督数据的情况下学习表示。

最近通过最大化节点和图表示之间的互信息 (MI) 来进行对比学习的工作在节点分类  和图分类任务。尽管如此，这些方法需要专门的编码器来学习图形或节点级别的表示。

**问题1：** 视觉领域应用数据增强。数据增强用于生成同一图像的多个视图以进行对比学习，在图像分类基准上取得了超越监督基线的最新结果。但是没有将这些技术应在图数据上。为了解决这个问题，作者引入了一种子健的方法来训练图编码器，方法是 最大化从图的不同结构视图编码的表示之间的MI。

为了进一步改进在节点和图上面的对比学习性能，作者系统研究了所提框架的主要组成部分，令人惊讶的表明，与视觉对比学习不同：

(1) 将视图数量（即增强）增加到两个以上的视图不会提高性能，并且通过对比来自一阶邻居的编码和一般图扩散来实现最佳性能;

(2) 与对比图-图或多尺度编码相比，跨视图对比节点和图编码在这两个任务上都取得了更好的结果;

(3) 与分层图池化方法（例如可微池化 (DiffPool)）相比，简单的图读出层在两个任务上都实现了更好的性能.

## 2 Related Work

### 2.1. Unsupervised Representation Learning on Graphs 

#### Random walks

通过随机游走将图变成序列，利用语言模型去学习节点表示。它们被证明以牺牲结构信息为代价过分强调邻近信息。此外，它们仅限于直推式设置，不能使用节点特征。

>Inductive learning，翻译成中文可以叫做 “归纳式学习”，顾名思义，就是从已有数据中归纳出模式来，应用于新的数据和任务。我们常用的机器学习模式，就是这样的：根据已有数据，学习分类器，然后应用于新的数据或任务。
>
>Transductive learning，翻译成中文可以叫做 “直推式学习”，指的是由当前学习的知识直接推广到给定的数据上。其实相当于是给了一些测试数据的情况下，结合已有的训练数据，看能不能推广到测试数据上。
>
>对应当下流行的学习任务：
>
>Inductive learning 对应于 meta-learning (元学习)，要求从诸多给定的任务和数据中学习通用的模式，迁移到未知的任务和数据上。
>
>Transductive learning 对应于 domain adaptation (领域自适应)，给定训练的数据包含了目标域数据，要求训练一个对目标域数据有最小误差的模型。

#### Graph kernels

将图分解为子结构并使用核函数来测量它们之间的图相似性。 然而，它们需要在子结构之间设计相似性度量的非平凡任务(non-trivial)。

> nontrivial 通常被工程师和数学家用来表示不明显或不容易证明的陈述或定理。
>
> Nontrivial 是程序员和计算机人描述任何不能快速和容易完成的任务。 这可能意味着“极其”困难和耗时。

#### Graph autoencoders (GAE)

训练编码器，通过预测一阶邻居，将图结构中节点的拓扑接近性强加到潜在空间。GAE 过分强调邻近信息并遭受非结构化预测的影响。

#### Contrastive methods

通过对比包含感兴趣依赖关系的分布和不包含感兴趣依赖关系的分布中的样本来测量潜在空间中的损失。**这些方法是无监督节点和图分类任务中当前最先进的方法。**Deep graph Infomax (DGI)将 deep InfoMax(DIM) 扩展到图，并通过对比节点学习节点表示，在节点分类基准测试中取得最先进的结果和图形编码。另一方面，InfoGraph (Sun et al., 2020) 扩展了深度 InfoMax 以学习图级表示，并在无监督图分类任务上优于以前的模型。**尽管这两种方法使用相同的对比学习方法，但它们使用了专门的编码器。**

### 2.2. Graph Diffusion Networks

图扩散网络(GDN)协调了空间消息传递和广义图扩散，其中作为去噪滤波的扩散允许消息通过高阶邻域。GDN 可以根据使用扩散的阶段分为**早期融合模型和晚期融合模型**。早起融合模型使用图扩散来决定邻居，例如图扩散卷积(GDC)将图卷积中的邻接矩阵替换为稀疏扩散矩阵。而后期融合模型节点特征投影到潜在空间中，然后基于扩散传播学习的表示。

### 2.3. Learning by Mutual Information Maximization

InfoMax 原则鼓励编码器学习表示，使输入和学习表示之间的 MI 最大化。对比预测编码 (CPC)对比有序局部特征的摘要以预测未来的局部特征，而深度 InfoMax (DIM) 同时对比单个摘要特征，即具有所有局部特征的全局特征。对比多视图编码 (CMC) ，增强multi-scale DIM (AMDIM)  和 SimCLR (Chen et al., 2020) 将 InfoMax 原理扩展到多视图和在由数据增强组合生成的视图中最大化 MI。**然而，结果表明这些模型的成功不仅仅归因于 MI 的属性，编码器和 MI 估计器的选择对性能有重大影响。**

## 3 Method

受视觉表示学习的多视图对比学习最新进展的启发，我们的方法通过最大化一个视图的节点表示和另一个视图的图表示之间的 MI 来学习节点和图表示，反之亦然，与对比全局或多视图相比，获得更好的结果 节点和图分类任务上的尺度编码。有如下几个模块：

![image-20220525111857144](https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/05/25/377fc68a8c1c71af089856f56bb961c5-image-20220525111857144-a933a0.png)

- 一种将样本图转换为同一图的相关视图的增强机制。我们只将增强应用于图的结构，而不是初始节点特征。随后是一个采样器，它从两个视图中对相同的节点进行子采样，即类似于视觉域中的裁剪。
- 两个专用的 GNN，即图编码器，每个视图一个，然后是一个共享的 MLP，即投影头，用于学习两个视图的节点表示。
- 一个图池化层，即读出函数，后跟一个共享的 MLP，即投影头，用于学习两个视图的图表示。
- 一种鉴别器，将来自一个视图的节点表示与来自另一个视图的图表示进行对比，反之亦然，并对它们之间的一致性进行评分。

### 3.1. Augmentations

最近在自我监督的视觉表示学习方面的工作表明，对比一致和不一致的图像视图可以让编码器学习丰富的表示。

定义图的视图是一个不容易的问题，这里作者考虑了两种增强：1) 对初始节点特征进行操作的特征空间增强，例如，mask或添加高斯噪声;2) 通过添加或删除连接性、子采样或使用最短距离或扩散矩阵生成全局视图，或者对图结构进行结构空间扩充和损坏。此外，我们观察到在任一空间上屏蔽或添加噪声都会降低性能。**基于以上，文本选择生成全局视图，然后进行子采样。**

在大多数情况下，通过将邻接矩阵转换为扩散矩阵并将这两个矩阵视为同一图结构的两个全等视图取得了不错的效果。我们推测，由于邻接矩阵和扩散矩阵分别提供了图结构的局部和全局视图，最大化从这两个视图学习的表示之间的一致性允许模型同时编码丰富的局部和全局信息。

扩散矩阵公式定义如下(具体参考Diffusion Improves Graph Learning)：

![image-20220525184743885](https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/05/25/74c80983b4bca1eca53c4f9813c8f9fb-image-20220525184743885-ee4d96.png)

![image-20220525192654140](https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/05/25/695de0ac0fe8e025be255d6584f80df3-image-20220525192654140-bffa52.png)

其中，$T \in \mathbb{R}^{n \times n}$ 是广义的转移矩阵，$\Theta$ 是全局-局部信息比例的加权系数。具体有两种可以设置的图扩散方法Personalized PageRank和heat kernel。

在子图采样过程中，从一个视图中随机进行节点和边采样，在另一个视图选择相同的节点和其节点对应的所有的边。**此过程允许我们的方法应用于具有不适合 GPU 内存的图的归纳任务，以及通过将子样本视为独立图的转换任务。** $S \in \mathbb R ^{n \times n}$ 代表一个图的diffsion矩阵。

### 3.2. Encoders

我们的框架允许在没有任何限制的情况下选择各种网络架构。本文选择简单并采用常用的图卷积网络 (GCN)作为该模型的基础图编码器。分别去学习两个视图里面的节点表示。

**节点表示：**经过GNN编码器和MLP后，导致两组节点表示 $H^α, H^β∈R^{n×d_h}$ 对应于同一图的两个全等视图。

**图表示：**对于每个视图，我们使用图池（读出）函数将 GNN 学习的节点表示聚合成图表示，在得到节点表示的时候，在经过投影头之前就拿出来用于下一步的图表示。然后将一个视图里面的全部的节点进行拼接(拼接为一行)，然后用一个映射，得到和节点相同维度的图中间表示。然后将这些表示馈送到一个共享的投影头这是一个具有两个隐藏层和 PReLU 非线性的 MLP，产生最终的图表示。**在推理时，将来自节点和图形级别的两个视图的表示相加作为最后的表示，用于下游任务。**

### 3.3. Training

为了端到端训练编码器并学习与下游任务无关的丰富节点和图级表示，我们利用Deep InfoMax (Hjelm et al., 2019)  方法最大化两个视图MI。实验证明，这种方法在节点和图分类基准上始终优于对比图或多尺度编码。

![image-20220525213748029](https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/05/25/d7b73a8f3e05a14209f564aa27889d0d-image-20220525213748029-215c39.png)

鉴别器是两个表示之间的点积： $D(\vec h_n, \vec h_g) = \vec h_n \cdot \vec h^T_g$ 。当鉴别器和投影头集成到双线性层中时，我们观察到节点分类基准略有改进。为了确定 MI 估计器，我们调查了四个估计器，并为每个基准选择了最好的一个。

为了在直推任务中生成负样本，我们随机打乱特征。最后，我们使用小批量随机梯度下降针对目标优化模型参数。

## 4. Experimental Results

### 4.1. Benchmarks

该文的使用了文献中广泛使用的三个节点分类和五个图分类。

![image-20220526091105326](https://raw.githubusercontent.com/zhiqiang00/Picbed/main/blog-images/2022/05/26/c17a0bf78b5e6d1eca454aa9f569230d-image-20220526091105326-2c6bbb.png)

### 4.2. Evaluation Protocol

对于节点分类，我们遵循DGI，并在50次训练之后使用线性模型报告测试节点的平均分类精度和标准差。

对于图的分类，我们遵循InfoGraph，并在5次运行后使用线性支持支持向量机报告10倍交叉验证的平均准确率和标准差。

此外，对于节点分类基准，我们在聚类评估协议下评估所提出的方法，并使用 K-Means 算法对学习的表示进行聚类。该文将集群的数量设置为真实类别的数量，并报告 50 次运行的平均归一化 MI (NMI) 和调整后的兰德指数 (ARI)。

### 4.3. Comparison with State-of-the-Art

### 4.4. Ablation Study

**4.4.1. EFFECT OF MUTUAL INFORMATION ESTIMATOR**

**4.4.2. EFFECT OF CONTRASTIVE MODE**

考虑了五种对比模式：localglobal, global-global, multi-scale, hybrid, and ensemble modes

在局部-全局模式下，我们扩展了Deep InfoMax (Hjelm et al.,  2019)，并将来自一个视图的节点编码与来自另一个视图的图形编码进行对比，反之亦然。

全局-全局模式类似于 (Li et al., 2019; Tian et  al., 2019; Chen et al.,  2020)，我们对比不同视图的图编码。

在多尺度模式下，我们将一个视图的图形编码与另一个视图的中间编码进行对比，反之亦然，我们还将一个视图的中间编码与另一视图的节点编码进行对比，反之亦然。

在混合模式下，我们同时使用本地-全局和全局-全局模式。

在集成模式下，我们对比来自同一视图的所有视图的节点和图形编码。

**4.4.3. EFFECT OF VIEWS**

来自邻接和 PPR 视图的对比编码在基准测试中表现更好。

增加视图数量不会单调地提高下游任务的性能。

**4.4.4. NEGATIVE SAMPLING & REGULARIZATION**

本文研究了批次大小的性能，其中一个大小为 N 的批次由 N-1 个负样本和 1 个正样本组成。我们观察到，在图分类中，增加批量大小会略微提高性能，而在节点分类中，它没有显着的效果。因此，**本文选择了有效的小批量**。为了在节点分类中生成负样本，我们考虑了两个损坏函数：（1）随机特征排列，和（2）邻接矩阵损坏。我们观察到，与后者或两者的结合相比，**应用前者可以取得明显更好的结果**。

此外，观察到应用标准化层，如 BatchNorm或 LayerNorm，或正则化方法，如添加高斯噪声、L2 正则化或 dropout )在预训练期间会降低下游任务的性能（早期停止除外）。

## 5 Conclusion

我们通过对比来自图的两个结构视图（包括一阶邻居和图扩散）的编码，引入了一种用于学习节点和图级别表示的自监督方法。我们表明，与视觉表示学习不同，增加视图数量或对比多尺度编码不会提高性能。使用这些发现，我们在线性评估协议下的 8 个节点和图形分类基准中的 8 个上实现了自我监督学习的最新技术水平，并在 8 个基准中的 4 个中优于强监督基线。在未来的工作中，我们计划研究该方法的大型预训练和迁移学习能力。









